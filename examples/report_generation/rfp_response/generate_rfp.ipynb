{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e8f1c8-44e8-461d-9a12-13e714448fa1",
   "metadata": {},
   "source": [
    "# RFP Response Generation Workflow\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_parse/blob/main/examples/report_generation/rfp_response/generate_rfp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook shows you how to build a workflow to generate a response to an RFP. \n",
    "\n",
    "In this scenario, we assume that you are Microsoft, and you are responding to the [JEDI Cloud RFP](https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf) put out by the federal government. The government is using the submitted responses to decide the best vendor for their needs.\n",
    "\n",
    "![generate_rfp_img](generate_rfp_img.png)\n",
    "\n",
    "We index a set of relevant documents that Microsoft has - including its annual report, wikipedia page on Microsoft Azure, a slide deck on the government cloud and cybersecurity capabilities. We then help you build an agentic workflow that can ingest an RFP, and generate a response for it in \n",
    "a way that adheres to its guidelines.\n",
    "\n",
    "We use LlamaParse to parse the context documents as well as the RFP document itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f28c6a-cb5e-4c16-bdc7-a69817fc4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7137b3-5b37-4e52-bc46-b994693d2664",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We download the [JEDI RFP template](https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf).\n",
    "\n",
    "We also download the context documents for Microsoft:\n",
    "1. Microsoft 2024 10-K \n",
    "2. Azure Wikipedia page\n",
    "3. A slide deck on Microsoft Azure Government\n",
    "4. Microsoft Digital Defense Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1310efa-1422-4214-b0bf-41b6e163fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download JEDI Cloud RFP Template\n",
    "!wget \"https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf\" -O data/jedi_cloud_rfp.pdf\n",
    "# microsoft annual report\n",
    "!wget \"https://www.dropbox.com/scl/fi/4v5dx8dc9yqc8k0yw5g4h/msft_10k_2024.pdf?rlkey=jdyfrsoyb18ztlq5msunmibns&st=9w6bdyvn&dl=1\" -O data/msft_10k_2024.pdf\n",
    "# !wget \"https://microsoft.gcs-web.com/static-files/1c864583-06f7-40cc-a94d-d11400c83cc8\" -O data/msft_10k_2024.pdf\n",
    "\n",
    "# azure wikipedia page\n",
    "!wget \"https://www.dropbox.com/scl/fi/7waur8ravmve3fe8nej0k/azure_wiki.pdf?rlkey=icru2w64oylx1p76ftt6y9irv&st=fr87vxob&dl=1\" -O data/azure_wiki.pdf\n",
    "# azure government slide deck\n",
    "!wget \"https://cdn.ymaws.com/flclerks.site-ym.com/resource/resmgr/2017_Fall_Conf/Presentations/2018-10-12_FCCC_Microsoft_Az.pdf\" -O data/azure_gov.pdf\n",
    "# microsoft cybersecurity capabilities\n",
    "!wget \"https://www.dropbox.com/scl/fi/qh00xz29rlom4md8ce675/microsoft_ddr.pdf?rlkey=d868nbnsu1ng41y1chw69y64b&st=24iqemb1&dl=1\" -O data/msft_ddr.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28f1ce-9618-47a2-9fc9-0502a382d841",
   "metadata": {},
   "source": [
    "We then parse the context documents with LlamaParse - we use multimodal mode in order to extract text from visual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cddd64-b886-4b0a-b010-2c0168b42147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "# use our multimodal models for extractions\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"anthropic-sonnet-3.5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85d79c-8835-4684-9883-f6342ceb44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = \"data\"\n",
    "data_out_dir = \"data_out_rfp\"\n",
    "\n",
    "!mkdir -p {data_dir}\n",
    "!mkdir -p {data_out_dir}\n",
    "\n",
    "# note: we skip the rfp doc, which will be indexed as part of the workflow\n",
    "files = [\"azure_gov.pdf\", \"azure_wiki.pdf\", \"msft_10k_2024.pdf\", \"msft_ddr.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24920ca-878e-4aae-89e2-8fe36b0fb06f",
   "metadata": {},
   "source": [
    "**Option 1**: If you haven't parsed the files yet, run the block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58cc182-663a-4b30-9a70-5af22acbe83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_dicts = {}\n",
    "\n",
    "for f in files:\n",
    "    file_base = Path(f).stem\n",
    "    full_file_path = str(Path(data_dir) / f)\n",
    "\n",
    "    file_docs = parser.load_data(full_file_path)\n",
    "\n",
    "    # attach metadata\n",
    "    for idx, d in enumerate(file_docs):\n",
    "        d.metadata[\"file_path\"] = f\n",
    "        d.metadata[\"page_num\"] = idx + 1\n",
    "\n",
    "    file_dicts[f] = {\"file_path\": full_file_path, \"docs\": file_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7e8ed-8c2a-4434-a7f9-e695dabc6158",
   "metadata": {},
   "source": [
    "#### Generate Summaries for each file \n",
    "\n",
    "Now that we've loaded the chunks for each file, let's now generate a summary for each file. These summaries will then be attached to the tool descriptions to help inform the agent on which files to query to fetch the right information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f8dda-4e55-4917-b277-63645b3b4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "summary_llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "for f in files:\n",
    "    print(f\">> Generate summary for file {f}\")\n",
    "    index = SummaryIndex(file_dicts[f][\"docs\"])\n",
    "    response = index.as_query_engine(llm=summary_llm).query(\n",
    "        \"Generate a short 1-2 line summary of this file to help inform an agent on what this file is about.\"\n",
    "    )\n",
    "    print(f\">> Generated summary: {str(response)}\")\n",
    "    file_dicts[f][\"summary\"] = str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fd045-f1a4-47c2-a773-718608d4c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(file_dicts, open(f\"{data_out_dir}/tmp_file_dicts.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93decb8b-acb6-42fb-b7ef-2a2b0d264da3",
   "metadata": {},
   "source": [
    "**Option 2**: If you've already run parsing, the files should be cached. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6849b-4572-4315-b7d5-77ad3b7ec351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_dicts = pickle.load(open(f\"{data_out_dir}/tmp_file_dicts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5000db-d5ca-4522-8dfa-bc64567b1884",
   "metadata": {},
   "source": [
    "### Build Indexes\n",
    "\n",
    "Once the text nodes are ready, we feed into our vector store, which will index these nodes into Chroma (you're welcome to use our other 40+ vector store integrations if you'd like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31409f-815d-4569-8b74-60fcec5af211",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101920ab-4054-4164-9f29-c3c9025c13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you want to recreate the index\n",
    "!rm -rf storage_rfp_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a2cb3-d21b-4ccf-81a0-1a83d0514a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "persist_dir = \"storage_rfp_chroma\"\n",
    "\n",
    "vector_store = ChromaVectorStore.from_params(\n",
    "    collection_name=\"rfp_docs\", persist_dir=persist_dir\n",
    ")\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f44aa-8dfa-4267-9489-d876ce056931",
   "metadata": {},
   "source": [
    "**NOTE**: Don't run the block below if you've already inserted the nodes. Only run if it's your first time!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcbaf7-9552-4ddb-9d7f-c499126c8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = [c for d in file_dicts.values() for c in d[\"docs\"]]\n",
    "index.insert_nodes(all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c4446-c477-4261-9747-c5294b0a54e9",
   "metadata": {},
   "source": [
    "### Define Retrievers\n",
    "\n",
    "Define retrievers, one for each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbac9ab-e3e2-448f-9e74-ad995415fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from typing import List\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# function tools\n",
    "def generate_tool(file: str, file_description: Optional[str] = None):\n",
    "    \"\"\"Return a function that retrieves only within a given file.\"\"\"\n",
    "    filters = MetadataFilters(\n",
    "        filters=[\n",
    "            MetadataFilter(key=\"file_path\", operator=FilterOperator.EQ, value=file),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def chunk_retriever_fn(query: str) -> str:\n",
    "        retriever = index.as_retriever(similarity_top_k=5, filters=filters)\n",
    "        nodes = retriever.retrieve(query)\n",
    "\n",
    "        full_text = \"\\n\\n========================\\n\\n\".join(\n",
    "            [n.get_content(metadata_mode=\"all\") for n in nodes]\n",
    "        )\n",
    "\n",
    "        return full_text\n",
    "\n",
    "    # define name as a function of the file\n",
    "    fn_name = Path(file).stem + \"_retrieve\"\n",
    "\n",
    "    tool_description = f\"Retrieves a small set of relevant document chunks from {file}.\"\n",
    "    if file_description is not None:\n",
    "        tool_description += f\"\\n\\nFile Description: {file_description}\"\n",
    "\n",
    "    tool = FunctionTool.from_defaults(\n",
    "        fn=chunk_retriever_fn, name=fn_name, description=tool_description\n",
    "    )\n",
    "\n",
    "    return tool\n",
    "\n",
    "\n",
    "# generate tools\n",
    "tools = []\n",
    "for f in files:\n",
    "    tools.append(generate_tool(f, file_description=file_dicts[f][\"summary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9106c7d-8c43-4443-a192-94d5f3a54ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Retrieves a small set of relevant document chunks from azure_gov.pdf.\\n\\nFile Description: This file provides an overview of Microsoft Azure Government, highlighting its secure and compliant cloud services tailored for U.S. government entities, along with features related to digital transformation, application innovation, and data-driven intelligence. It also outlines compliance standards, service models, and the commitment to security and privacy.', name='azure_gov_retrieve', fn_schema=<class 'llama_index.core.tools.utils.azure_gov_retrieve'>, return_direct=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate an existing function\n",
    "tools[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ebbad-3200-4818-aa48-705eda21503e",
   "metadata": {},
   "source": [
    "## Build Workflow\n",
    "\n",
    "Let's build a workflow that can iterate through the extracted keys/questions from the RFP, and fill them out! \n",
    "\n",
    "The user specifies an RFP document as input. The workflow then goes through the following steps:\n",
    "1. We parse the RFP template using LlamaParse\n",
    "2. We then extract out the relevant questions we'd want to ask the knowledge base given the instructions in the RFP\n",
    "3. For each question, we query the knowledge base using a specialized agent to generate a response. The agent is equipped with a set of retrieval tools over the data.\n",
    "4. We concatenate the questions/answers into a list of dictionaries.\n",
    "5. Given the question/answer pairs, we feed it along with the source RFP template into a prompt to generate the final report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740535e8-714b-4744-a515-5007834eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from llama_index.core.llms import LLM\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "import logging\n",
    "import json\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "_logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# this is the research agent's system prompt, tasked with answering a specific question\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a research agent tasked with filling out a specific form key/question with the appropriate value, given a bank of context.\n",
    "You are given a specific form key/question. Think step-by-step and use the existing set of tools to help answer the question.\n",
    "\n",
    "You MUST always use at least one tool to answer each question. Only after you've determined that existing tools do not \\\n",
    "answer the question should you try to reason from first principles and prior knowledge to answer the question.\n",
    "\n",
    "You MUST try to answer the question instead of only saying 'I dont know'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the prompt tasked with extracting information from an RFP file.\n",
    "EXTRACT_KEYS_PROMPT = \"\"\"\\\n",
    "You are provided an entire RFP document, or a large subsection from it. \n",
    "\n",
    "We wish to generate a response to the RFP in a way that adheres to the instructions within the RFP, \\\n",
    "including the specific sections that an RFP response should contain, and the content that would need to go \\\n",
    "into each section.\n",
    "\n",
    "Your task is to extract out a list of \"questions\", where each question corresponds to a specific section that is required in the RFP response.\n",
    "Put another way, after we extract out the questions we will go through each question and answer each one \\\n",
    "with our downstream research assistant, and the combined\n",
    "question:answer pairs will constitute the full RFP response.\n",
    "\n",
    "- Make sure the questions are comprehensive and adheres to the RFP requirements.\n",
    "- Make sure each question is descriptive - this gives our downstream assistant context to fill out the value for that question \n",
    "- Extract out all the questions as a list of strings.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# this is the prompt that generates the final RFP response given the original template text and question-answer pairs.\n",
    "GENERATE_OUTPUT_PROMPT = \"\"\"\\\n",
    "You are an expert analyst.\n",
    "Your task is to generate an RFP response according to the given RFP and question/answer pairs.\n",
    "\n",
    "You are given the following RFP and qa pairs:\n",
    "\n",
    "<rfp_document>\n",
    "{output_template}\n",
    "</rfp_document>\n",
    "\n",
    "<question_answer_pairs>\n",
    "{answers}\n",
    "</question_answer_pairs>\n",
    "\n",
    "Not every question has an appropriate answer. This is because the agent tasked with answering the question did not have the right context to answer it.\n",
    "If this is the case, you MUST come up with an answer that is reasonable. You CANNOT say that you are unsure in any area of the RFP response.\n",
    "\n",
    "\n",
    "Please generate the output according to the template and the answers, in markdown format.\n",
    "Directly output the generated markdown content, do not add any additional text, such as \"```markdown\" or \"Here is the output:\".\n",
    "Follow the original format of the template as closely as possible, and fill in the answers into the appropriate sections.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class OutputQuestions(BaseModel):\n",
    "    \"\"\"List of keys that make up the sections of the RFP response.\"\"\"\n",
    "\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class OutputTemplateEvent(Event):\n",
    "    docs: List[Document]\n",
    "\n",
    "\n",
    "class QuestionsExtractedEvent(Event):\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class HandleQuestionEvent(Event):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class QuestionAnsweredEvent(Event):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class CollectedAnswersEvent(Event):\n",
    "    combined_answers: str\n",
    "\n",
    "\n",
    "class LogEvent(Event):\n",
    "    msg: str\n",
    "    delta: bool = False\n",
    "\n",
    "\n",
    "class RFPWorkflow(Workflow):\n",
    "    \"\"\"RFP workflow.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tools,\n",
    "        parser: LlamaParse,\n",
    "        llm: LLM | None = None,\n",
    "        similarity_top_k: int = 20,\n",
    "        output_dir: str = data_out_dir,\n",
    "        agent_system_prompt: str = AGENT_SYSTEM_PROMPT,\n",
    "        generate_output_prompt: str = GENERATE_OUTPUT_PROMPT,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.tools = tools\n",
    "\n",
    "        self.parser = parser\n",
    "\n",
    "        self.llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self.agent_system_prompt = agent_system_prompt\n",
    "\n",
    "        # if not exists, create\n",
    "        out_path = Path(self.output_dir) / \"workflow_output\"\n",
    "        if not out_path.exists():\n",
    "            out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.generate_output_prompt = PromptTemplate(generate_output_prompt)\n",
    "\n",
    "    @step\n",
    "    async def parse_output_template(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> OutputTemplateEvent:\n",
    "        # load output template file\n",
    "        out_template_path = Path(\n",
    "            f\"{self.output_dir}/workflow_output/output_template.jsonl\"\n",
    "        )\n",
    "        if out_template_path.exists():\n",
    "            with open(out_template_path, \"r\") as f:\n",
    "                docs = [Document.model_validate_json(line) for line in f]\n",
    "        else:\n",
    "            docs = await self.parser.aload_data(ev.rfp_template_path)\n",
    "            # save output template to file\n",
    "            with open(out_template_path, \"w\") as f:\n",
    "                for doc in docs:\n",
    "                    f.write(doc.model_dump_json())\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "        await ctx.set(\"output_template\", docs)\n",
    "        return OutputTemplateEvent(docs=docs)\n",
    "\n",
    "    @step\n",
    "    async def extract_questions(\n",
    "        self, ctx: Context, ev: OutputTemplateEvent\n",
    "    ) -> HandleQuestionEvent:\n",
    "        docs = ev.docs\n",
    "\n",
    "        # save all_questions to file\n",
    "        out_keys_path = Path(f\"{self.output_dir}/workflow_output/all_keys.txt\")\n",
    "        if out_keys_path.exists():\n",
    "            with open(out_keys_path, \"r\") as f:\n",
    "                output_qs = [q.strip() for q in f.readlines()]\n",
    "        else:\n",
    "            # try stuffing all text into the prompt\n",
    "            all_text = \"\\n\\n\".join([d.get_content(metadata_mode=\"all\") for d in docs])\n",
    "            prompt = PromptTemplate(template=EXTRACT_KEYS_PROMPT)\n",
    "\n",
    "            try:\n",
    "                output_qs = self.llm.structured_predict(\n",
    "                    OutputQuestions, prompt, context=all_text\n",
    "                ).questions\n",
    "            except Exception as e:\n",
    "                _logger.error(f\"Error extracting questions from page: {all_text}\")\n",
    "                _logger.error(e)\n",
    "\n",
    "            with open(out_keys_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(output_qs))\n",
    "\n",
    "        await ctx.set(\"num_to_collect\", len(output_qs))\n",
    "\n",
    "        for question in output_qs:\n",
    "            ctx.send_event(HandleQuestionEvent(question=question))\n",
    "\n",
    "        return None\n",
    "\n",
    "    @step\n",
    "    async def handle_question(\n",
    "        self, ctx: Context, ev: HandleQuestionEvent\n",
    "    ) -> QuestionAnsweredEvent:\n",
    "        question = ev.question\n",
    "\n",
    "        # initialize a Function Calling \"research\" agent where given a task, it can pull responses from relevant tools and synthesize over it\n",
    "        research_agent = FunctionCallingAgentWorker.from_tools(\n",
    "            tools, llm=llm, verbose=False, system_prompt=self.agent_system_prompt\n",
    "        ).as_agent()\n",
    "\n",
    "        # ensure the agent's memory is cleared\n",
    "        response = await research_agent.aquery(question)\n",
    "\n",
    "        if self._verbose:\n",
    "            # instead of printing the message directly, write the event to stream!\n",
    "            msg = f\">> Asked question: {question}\\n>> Got response: {str(response)}\"\n",
    "            ctx.write_event_to_stream(LogEvent(msg=msg))\n",
    "\n",
    "        return QuestionAnsweredEvent(question=question, answer=str(response))\n",
    "\n",
    "    @step\n",
    "    async def combine_answers(\n",
    "        self, ctx: Context, ev: QuestionAnsweredEvent\n",
    "    ) -> CollectedAnswersEvent:\n",
    "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
    "        results = ctx.collect_events(ev, [QuestionAnsweredEvent] * num_to_collect)\n",
    "        if results is None:\n",
    "            return None\n",
    "\n",
    "        combined_answers = \"\\n\".join([result.model_dump_json() for result in results])\n",
    "        # save combined_answers to file\n",
    "        with open(\n",
    "            f\"{self.output_dir}/workflow_output/combined_answers.jsonl\", \"w\"\n",
    "        ) as f:\n",
    "            f.write(combined_answers)\n",
    "\n",
    "        return CollectedAnswersEvent(combined_answers=combined_answers)\n",
    "\n",
    "    @step\n",
    "    async def generate_output(\n",
    "        self, ctx: Context, ev: CollectedAnswersEvent\n",
    "    ) -> StopEvent:\n",
    "        output_template = await ctx.get(\"output_template\")\n",
    "        output_template = \"\\n\".join(\n",
    "            [doc.get_content(\"none\") for doc in output_template]\n",
    "        )\n",
    "\n",
    "        if self._verbose:\n",
    "            ctx.write_event_to_stream(LogEvent(msg=\">> GENERATING FINAL OUTPUT\"))\n",
    "\n",
    "        resp = await self.llm.astream(\n",
    "            self.generate_output_prompt,\n",
    "            output_template=output_template,\n",
    "            answers=ev.combined_answers,\n",
    "        )\n",
    "\n",
    "        final_output = \"\"\n",
    "        async for r in resp:\n",
    "            ctx.write_event_to_stream(LogEvent(msg=r, delta=True))\n",
    "            final_output += r\n",
    "\n",
    "        # save final_output to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/final_output.md\", \"w\") as f:\n",
    "            f.write(final_output)\n",
    "\n",
    "        return StopEvent(result=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895c3b1-6ea1-41c3-bcf9-e42c2a4beb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "workflow = RFPWorkflow(\n",
    "    tools,\n",
    "    parser=parser,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    timeout=None,  # don't worry about timeout to make sure it completes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb19c4-9133-4a3f-b0bd-adf14399e21b",
   "metadata": {},
   "source": [
    "#### Visualize the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35ed08-edc1-4bd3-b80d-6e745367128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfp_workflow.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(RFPWorkflow, filename=\"rfp_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2effc-350a-46e6-b325-45c1b24b6e89",
   "metadata": {},
   "source": [
    "## Run the Workflow\n",
    "\n",
    "Let's run the full workflow and generate the output! \n",
    "\n",
    "This will take 5-20 minutes to run and complete. You can inspect the intermediate verbose outputs below as the intermediate questions/answers are generated. The response is streamed back to the user at the end - the response itself is quite long so will take a while to complete! You can also integrate with an observability provider like LlamaTrace/Arize Phoenix in order to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7db55-aff9-4d20-aa13-4e0931b39f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step parse_output_template\n",
      "Step parse_output_template produced event OutputTemplateEvent\n",
      "Running step extract_questions\n",
      "Step extract_questions produced no event\n",
      "Running step handle_question\n",
      "Running step handle_question\n",
      "Running step handle_question\n",
      "Running step handle_question\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the specific deliverables required for this project?\n",
      ">> Got response: To determine the specific deliverables required for the project, I need more context about the project itself. Could you please provide more details or specify the project you are referring to?\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What is the overall project scope and objectives as outlined in the RFP?\n",
      ">> Got response: To answer this question, I would need to access the specific RFP document related to the project you are referring to. Could you please provide more details or specify the document you are referring to?\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What is the budget range for the project, and what are the payment terms?\n",
      ">> Got response: To answer your question about the budget range for the project and the payment terms, I would need more specific context or a document related to the project you are referring to. Could you please provide more details or specify the document or context in which this project is mentioned?\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What is the timeline for the project, including key milestones and deadlines?\n",
      ">> Got response: The retrieved documents do not provide a specific timeline for a project, including key milestones and deadlines. They contain various timelines related to Microsoft's history, product launches, and strategic initiatives, but none specifically outline a project timeline with milestones and deadlines.\n",
      "\n",
      "If you have a specific project in mind, please provide more details so I can assist you better. Alternatively, if you are looking for general information on how Microsoft or Azure typically handles project timelines, I can help with that as well.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the evaluation criteria that will be used to assess proposals?\n",
      ">> Got response: The retrieved documents did not provide specific information on the evaluation criteria used to assess proposals. Based on my training data, evaluation criteria for proposals typically include factors such as:\n",
      "\n",
      "1. **Technical Merit**: The feasibility, innovation, and technical approach of the proposal.\n",
      "2. **Cost-Effectiveness**: The budget and financial plan, ensuring it is reasonable and justified.\n",
      "3. **Experience and Qualifications**: The expertise and past performance of the proposing team or organization.\n",
      "4. **Compliance and Risk Management**: Adherence to regulatory requirements and the ability to manage potential risks.\n",
      "5. **Impact and Benefits**: The potential positive outcomes and benefits of the proposal for the intended stakeholders.\n",
      "\n",
      "For specific criteria related to a particular organization or context, it would be best to refer to the official request for proposals (RFP) document or guidelines provided by the issuing entity.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the qualifications and experience required for the project team members?\n",
      ">> Got response: The qualifications and experience required for project team members in the context of Microsoft and Azure can vary depending on the specific roles and responsibilities within a project. Here are some insights based on the retrieved documents:\n",
      "\n",
      "1. **Azure Certifications and Roles**:\n",
      "   - Microsoft offers a variety of certifications for different roles, such as Azure Data Scientist Associate, Azure Database Administrator Associate, Azure Developer Associate, Azure Security Engineer Associate, and more. These certifications indicate a level of expertise in specific areas of Azure services and solutions.\n",
      "\n",
      "2. **Cybersecurity Skills**:\n",
      "   - There is a significant demand for cybersecurity professionals, and Microsoft has initiatives to address the skills gap. Training and certification in cybersecurity are crucial, and Microsoft collaborates with various organizations to provide training and certification opportunities.\n",
      "\n",
      "3. **Diversity and Inclusion**:\n",
      "   - Microsoft emphasizes the importance of diversity and inclusion in its workforce. The company aims to recruit and retain talent from diverse backgrounds and experiences, which is crucial for fostering innovation and success.\n",
      "\n",
      "4. **Technical and Industry Skills**:\n",
      "   - For roles related to security and threat intelligence, deep technical and industry skills are required. Teams like the Security Service Line (SSL) and Microsoft Security Response Center (MSRC) provide specialized services and require expertise in incident response, threat intelligence, and cyber resilience.\n",
      "\n",
      "5. **AI and Quantum Computing**:\n",
      "   - With the rise of AI and quantum computing, skills in these areas are becoming increasingly important. Microsoft offers initiatives and training programs to develop AI skills, which are essential for leveraging AI technologies effectively.\n",
      "\n",
      "6. **Project Management and Collaboration**:\n",
      "   - For roles involving project management and collaboration, skills in managing and coordinating projects, as well as working with diverse teams, are important. Microsoft Teams and other collaboration tools are used to facilitate communication and project execution.\n",
      "\n",
      "Overall, the qualifications and experience required for project team members at Microsoft and Azure involve a combination of technical expertise, certifications, diversity and inclusion awareness, and skills in emerging technologies like AI and cybersecurity.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What are the specific requirements for project management and reporting?\n",
      ">> Got response: The specific requirements for project management and reporting, particularly in the context of Microsoft and its cloud services, can be derived from various compliance and operational standards. Here are some key points:\n",
      "\n",
      "1. **Compliance and Security**: Microsoft has committed to various compliance standards such as CJIS (Criminal Justice Information Services) for law enforcement agencies, which includes requirements for personnel security, security training, and adherence to security policies. This is crucial for project management in sectors dealing with sensitive information.\n",
      "\n",
      "2. **Operational Risks**: Microsoft emphasizes the importance of maintaining a robust operations infrastructure to handle user traffic, service growth, and product complexity. This includes ensuring adequate data center capacity, internet connectivity, and power supply, which are critical for project management and reporting in cloud services.\n",
      "\n",
      "3. **Regulatory Requirements**: Microsoft is subject to a wide range of legal and regulatory requirements globally, including those related to data privacy, cybersecurity, and telecommunications. These regulations impact how projects are managed and reported, especially in terms of data handling and compliance.\n",
      "\n",
      "4. **Metrics and Reporting**: Microsoft uses various metrics to assess business performance and make informed decisions. These metrics are disclosed to provide transparency and reflect the evolution of products and services. This is part of the project management and reporting process to ensure alignment with business goals.\n",
      "\n",
      "5. **Cybersecurity and Infrastructure Resilience**: There are ongoing efforts to improve cybersecurity and infrastructure resilience, which include regulatory initiatives and standards for IoT and OT device security. These initiatives impact project management by setting requirements for security practices and reporting.\n",
      "\n",
      "6. **Supply Chain and Development Infrastructure**: Microsoft has developed tools and practices to secure its development infrastructure, including threat modeling and adopting secure boot for build machines. These practices are part of project management to ensure secure and efficient software development and deployment.\n",
      "\n",
      "These points highlight the multifaceted nature of project management and reporting requirements, which encompass compliance, operational efficiency, regulatory adherence, and security measures.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What are the expectations for communication and collaboration with the client?\n",
      ">> Got response: The expectations for communication and collaboration with clients, particularly in the context of Microsoft and its cloud services, can be summarized as follows:\n",
      "\n",
      "1. **Collaboration and Compliance**: Microsoft emphasizes the importance of collaboration with clients to ensure compliance with regulatory requirements. For example, in the context of the Criminal Justice Information Services (CJIS) Security Policy, Microsoft collaborates with law enforcement agencies to meet compliance requirements, such as background checks and security training (azure_gov.pdf).\n",
      "\n",
      "2. **Communication Services**: Microsoft Azure offers communication services that enable the creation of web and mobile communication applications, including SMS, video calling, and web-based chat. These services facilitate effective communication and collaboration with clients (azure_wiki.pdf).\n",
      "\n",
      "3. **Productivity and Collaboration Tools**: Microsoft provides a suite of productivity and collaboration tools, such as Microsoft 365, Dynamics 365, and Microsoft Teams, which are designed to enhance communication and collaboration within organizations. These tools help empower employees, optimize operations, and engage customers (msft_10k_2024.pdf).\n",
      "\n",
      "4. **Collective Defense and Cybersecurity**: Microsoft emphasizes the importance of collaboration in cybersecurity, working with partners across the industry to enhance collective defense efforts. This includes sharing threat intelligence and developing strategies to combat cyber threats (msft_ddr.pdf).\n",
      "\n",
      "Overall, Microsoft prioritizes secure, compliant, and effective communication and collaboration with clients through its suite of tools and services, while also emphasizing the importance of partnerships and collective efforts in cybersecurity.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What are the terms and conditions related to confidentiality and data protection?\n",
      ">> Got response: The terms and conditions related to confidentiality and data protection for Microsoft Azure and its services are outlined in various documents and reports. Here are some key points:\n",
      "\n",
      "1. **Compliance and Certifications**: Microsoft Azure complies with numerous global, U.S. government, industry, and regional certifications and compliance standards, such as ISO 27001, FedRAMP, HIPAA, and GDPR. These standards ensure that Azure services meet stringent data protection and confidentiality requirements.\n",
      "\n",
      "2. **Data Sovereignty and Privacy**: Azure Government ensures data sovereignty by keeping data within the U.S. and is operated by screened U.S. persons. Microsoft emphasizes security, privacy, control, compliance, transparency, and reliability in its services.\n",
      "\n",
      "3. **Legal and Regulatory Challenges**: Microsoft faces evolving legal requirements related to data protection, such as the EU General Data Protection Regulation (GDPR) and other international data privacy laws. These regulations impose compliance obligations on Microsoft regarding the handling of personal data.\n",
      "\n",
      "4. **Security Measures**: Microsoft is committed to protecting user data from cyberattacks and unauthorized access. This includes designing products that prioritize security, privacy, integrity, and reliability. Microsoft also opposes cyberattacks on innocent citizens and enterprises.\n",
      "\n",
      "5. **Data Breaches and Liability**: Despite efforts to secure data, Microsoft acknowledges the risk of data breaches and the potential for legal exposure. The company advocates for transparency in government data requests and emphasizes the importance of protecting customer data.\n",
      "\n",
      "6. **Partnerships and Collaboration**: Microsoft collaborates with various organizations to enhance cybersecurity and protect against cyber threats. This includes initiatives like the Cybersecurity Tech Accord, which aims to protect users from cyber threats and promote responsible nation-state behavior.\n",
      "\n",
      "These points highlight Microsoft's commitment to confidentiality and data protection through compliance with international standards, legal obligations, and proactive security measures.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What are the risks associated with the project, and how will they be managed?\n",
      ">> Got response: The risks associated with Microsoft's projects, as outlined in the retrieved documents, include a variety of operational, economic, legal, regulatory, and cybersecurity risks. Here's a summary of the key risks and how they are managed:\n",
      "\n",
      "1. **Operational Risks**:\n",
      "   - **Infrastructure and Service Disruptions**: Microsoft faces risks related to outages, data losses, and disruptions due to inadequate operations infrastructure. To manage these, Microsoft invests in building, purchasing, or leasing data centers and equipment, and upgrading technology and network infrastructure.\n",
      "   - **Quality and Supply Problems**: Risks include defects in hardware and software products, and limited suppliers for certain components. Microsoft manages these risks through design, testing, warranty repairs, and maintaining a diversified supply chain.\n",
      "\n",
      "2. **Economic and Geopolitical Risks**:\n",
      "   - **Global Business Exposure**: Microsoft's international operations expose it to economic and geopolitical risks, such as currency fluctuations and political instability. The company hedges a portion of its international currency exposure and monitors global developments.\n",
      "   - **Catastrophic Events**: Events like earthquakes, pandemics, or geopolitical conflicts could disrupt business operations. Microsoft emphasizes business continuity management and resilience planning.\n",
      "\n",
      "3. **Legal, Regulatory, and Litigation Risks**:\n",
      "   - **Competition and Antitrust**: Microsoft is subject to scrutiny under competition laws, which may affect product design and marketing. The company engages with regulators and adapts its strategies to comply with legal requirements.\n",
      "\n",
      "4. **Cybersecurity Risks**:\n",
      "   - **Supply Chain Security**: Microsoft addresses risks from supply chain attacks through supplier audits, education, and awareness training. It also collaborates internationally to develop security norms and regulations.\n",
      "   - **Infrastructure Resilience**: Microsoft invests in cybersecurity measures, such as Zero Trust principles, secure boot for build machines, and threat modeling for its DevOps environment.\n",
      "\n",
      "5. **Intellectual Property Risks**:\n",
      "   - **Protection and Utilization**: Microsoft faces challenges in protecting its intellectual property globally. The company manages these risks through licensing agreements, legal actions, and engagement with open-source software.\n",
      "\n",
      "6. **General Risks**:\n",
      "   - **Reputation and Brand Damage**: Risks include product safety issues, data breaches, and public scrutiny. Microsoft manages these through proactive communication, compliance, and maintaining high standards for product quality and safety.\n",
      "\n",
      "Overall, Microsoft employs a combination of strategic investments, regulatory compliance, risk management frameworks, and technological innovations to manage these risks effectively.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced event CollectedAnswersEvent\n",
      "Running step generate_output\n",
      ">> GENERATING FINAL OUTPUT\n",
      "# Response to JEDI Cloud RFP # HQ0034-18-R-0077\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Our proposal for the JEDI Cloud project is designed to meet the Department of Defense's requirements for a robust, secure, and scalable cloud infrastructure. We leverage our extensive experience in cloud services to deliver a solution that ensures high availability, data security, and seamless integration with existing DoD systems. Our approach emphasizes compliance with all regulatory requirements, including those related to data protection and confidentiality, while providing a flexible and cost-effective solution.\n",
      "\n",
      "## Project Scope and Objectives\n",
      "\n",
      "The JEDI Cloud project aims to provide the Department of Defense with a comprehensive cloud infrastructure that supports both unclassified and classified data processing. The primary objectives include:\n",
      "\n",
      "- Delivering Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) offerings that meet the DoD's operational requirements.\n",
      "- Ensuring high availability and failover capabilities across multiple data centers.\n",
      "- Providing secure data transfer and logical isolation to protect sensitive information.\n",
      "- Supporting tactical edge operations with portable and ruggedized compute and storage solutions.\n",
      "\n",
      "## Deliverables\n",
      "\n",
      "The specific deliverables for this project include:\n",
      "\n",
      "- Unclassified and Classified IaaS and PaaS offerings.\n",
      "- Cloud Support Packages for both unclassified and classified environments.\n",
      "- A comprehensive Portability Plan and Portability Test to ensure data and application mobility.\n",
      "- Program Management Support for the Cloud Computing Program Office (CCPO).\n",
      "\n",
      "## Budget and Payment Terms\n",
      "\n",
      "The maximum contract limit for the JEDI Cloud ID/IQ Contract is $10,000,000,000.00, with a minimum guaranteed award amount of $1,000,000.00. All task orders will be firm-fixed price, and payment terms will be structured according to the delivery and acceptance of specific contract line items.\n",
      "\n",
      "## Timeline and Milestones\n",
      "\n",
      "The project is structured with a two-year base ordering period, followed by two three-year option periods and one two-year option period, for a total potential duration of 10 years. Key milestones include:\n",
      "\n",
      "- Initial setup and configuration of cloud infrastructure within the first six months.\n",
      "- Completion of the Portability Plan and Test within the first year.\n",
      "- Full operational capability for tactical edge solutions by the end of the second year.\n",
      "\n",
      "## Evaluation Criteria\n",
      "\n",
      "Proposals will be evaluated based on the following criteria:\n",
      "\n",
      "1. Technical Merit: The feasibility and innovation of the proposed solution.\n",
      "2. Cost-Effectiveness: The reasonableness and justification of the proposed budget.\n",
      "3. Experience and Qualifications: The expertise and past performance of the project team.\n",
      "4. Compliance and Risk Management: Adherence to regulatory requirements and risk mitigation strategies.\n",
      "5. Impact and Benefits: The potential positive outcomes for the DoD.\n",
      "\n",
      "## Project Team Qualifications\n",
      "\n",
      "Our project team comprises highly qualified professionals with extensive experience in cloud services, cybersecurity, and program management. Key team members hold relevant certifications, such as Azure Developer Associate and Azure Security Engineer Associate, ensuring expertise in delivering secure and efficient cloud solutions.\n",
      "\n",
      "## Project Management and Reporting\n",
      "\n",
      "We will implement a robust project management framework that includes:\n",
      "\n",
      "- Regular progress reports and performance metrics to ensure transparency and accountability.\n",
      "- Compliance with all security and data protection standards, including CJIS and FedRAMP.\n",
      "- A Quality Assurance Surveillance Plan (QASP) to monitor and maintain performance metrics.\n",
      "\n",
      "## Communication and Collaboration\n",
      "\n",
      "We prioritize effective communication and collaboration with the DoD through:\n",
      "\n",
      "- Regular meetings and updates to ensure alignment with project objectives.\n",
      "- Use of Microsoft Teams and other collaboration tools to facilitate seamless interaction.\n",
      "- A dedicated point of contact for all project-related inquiries and coordination.\n",
      "\n",
      "## Confidentiality and Data Protection\n",
      "\n",
      "We are committed to maintaining the highest standards of confidentiality and data protection, as outlined in our compliance with ISO 27001, GDPR, and other relevant standards. Our approach includes:\n",
      "\n",
      "- Secure data storage and transfer protocols.\n",
      "- Regular audits and assessments to ensure compliance with all regulatory requirements.\n",
      "- A comprehensive incident response plan to address any potential data breaches.\n",
      "\n",
      "## Risk Management\n",
      "\n",
      "We have identified key risks associated with the project, including operational disruptions, cybersecurity threats, and compliance challenges. Our risk management strategy includes:\n",
      "\n",
      "- Investing in infrastructure resilience and cybersecurity measures.\n",
      "- Engaging with regulators to ensure compliance with all legal requirements.\n",
      "- Implementing a robust supply chain management process to mitigate risks related to hardware and software components.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Our proposal for the JEDI Cloud project offers a comprehensive solution that meets the Department of Defense's requirements for a secure, scalable, and cost-effective cloud infrastructure. We are committed to delivering exceptional value and ensuring the success of the JEDI Cloud initiative.Step generate_output produced event StopEvent\n",
      "# Response to JEDI Cloud RFP # HQ0034-18-R-0077\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Our proposal for the JEDI Cloud project is designed to meet the Department of Defense's requirements for a robust, secure, and scalable cloud infrastructure. We leverage our extensive experience in cloud services to deliver a solution that ensures high availability, data security, and seamless integration with existing DoD systems. Our approach emphasizes compliance with all regulatory requirements, including those related to data protection and confidentiality, while providing a flexible and cost-effective solution.\n",
      "\n",
      "## Project Scope and Objectives\n",
      "\n",
      "The JEDI Cloud project aims to provide the Department of Defense with a comprehensive cloud infrastructure that supports both unclassified and classified data processing. The primary objectives include:\n",
      "\n",
      "- Delivering Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) offerings that meet the DoD's operational requirements.\n",
      "- Ensuring high availability and failover capabilities across multiple data centers.\n",
      "- Providing secure data transfer and logical isolation to protect sensitive information.\n",
      "- Supporting tactical edge operations with portable and ruggedized compute and storage solutions.\n",
      "\n",
      "## Deliverables\n",
      "\n",
      "The specific deliverables for this project include:\n",
      "\n",
      "- Unclassified and Classified IaaS and PaaS offerings.\n",
      "- Cloud Support Packages for both unclassified and classified environments.\n",
      "- A comprehensive Portability Plan and Portability Test to ensure data and application mobility.\n",
      "- Program Management Support for the Cloud Computing Program Office (CCPO).\n",
      "\n",
      "## Budget and Payment Terms\n",
      "\n",
      "The maximum contract limit for the JEDI Cloud ID/IQ Contract is $10,000,000,000.00, with a minimum guaranteed award amount of $1,000,000.00. All task orders will be firm-fixed price, and payment terms will be structured according to the delivery and acceptance of specific contract line items.\n",
      "\n",
      "## Timeline and Milestones\n",
      "\n",
      "The project is structured with a two-year base ordering period, followed by two three-year option periods and one two-year option period, for a total potential duration of 10 years. Key milestones include:\n",
      "\n",
      "- Initial setup and configuration of cloud infrastructure within the first six months.\n",
      "- Completion of the Portability Plan and Test within the first year.\n",
      "- Full operational capability for tactical edge solutions by the end of the second year.\n",
      "\n",
      "## Evaluation Criteria\n",
      "\n",
      "Proposals will be evaluated based on the following criteria:\n",
      "\n",
      "1. Technical Merit: The feasibility and innovation of the proposed solution.\n",
      "2. Cost-Effectiveness: The reasonableness and justification of the proposed budget.\n",
      "3. Experience and Qualifications: The expertise and past performance of the project team.\n",
      "4. Compliance and Risk Management: Adherence to regulatory requirements and risk mitigation strategies.\n",
      "5. Impact and Benefits: The potential positive outcomes for the DoD.\n",
      "\n",
      "## Project Team Qualifications\n",
      "\n",
      "Our project team comprises highly qualified professionals with extensive experience in cloud services, cybersecurity, and program management. Key team members hold relevant certifications, such as Azure Developer Associate and Azure Security Engineer Associate, ensuring expertise in delivering secure and efficient cloud solutions.\n",
      "\n",
      "## Project Management and Reporting\n",
      "\n",
      "We will implement a robust project management framework that includes:\n",
      "\n",
      "- Regular progress reports and performance metrics to ensure transparency and accountability.\n",
      "- Compliance with all security and data protection standards, including CJIS and FedRAMP.\n",
      "- A Quality Assurance Surveillance Plan (QASP) to monitor and maintain performance metrics.\n",
      "\n",
      "## Communication and Collaboration\n",
      "\n",
      "We prioritize effective communication and collaboration with the DoD through:\n",
      "\n",
      "- Regular meetings and updates to ensure alignment with project objectives.\n",
      "- Use of Microsoft Teams and other collaboration tools to facilitate seamless interaction.\n",
      "- A dedicated point of contact for all project-related inquiries and coordination.\n",
      "\n",
      "## Confidentiality and Data Protection\n",
      "\n",
      "We are committed to maintaining the highest standards of confidentiality and data protection, as outlined in our compliance with ISO 27001, GDPR, and other relevant standards. Our approach includes:\n",
      "\n",
      "- Secure data storage and transfer protocols.\n",
      "- Regular audits and assessments to ensure compliance with all regulatory requirements.\n",
      "- A comprehensive incident response plan to address any potential data breaches.\n",
      "\n",
      "## Risk Management\n",
      "\n",
      "We have identified key risks associated with the project, including operational disruptions, cybersecurity threats, and compliance challenges. Our risk management strategy includes:\n",
      "\n",
      "- Investing in infrastructure resilience and cybersecurity measures.\n",
      "- Engaging with regulators to ensure compliance with all legal requirements.\n",
      "- Implementing a robust supply chain management process to mitigate risks related to hardware and software components.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Our proposal for the JEDI Cloud project offers a comprehensive solution that meets the Department of Defense's requirements for a secure, scalable, and cost-effective cloud infrastructure. We are committed to delivering exceptional value and ensuring the success of the JEDI Cloud initiative.\n"
     ]
    }
   ],
   "source": [
    "handler = workflow.run(rfp_template_path=str(Path(data_dir) / \"jedi_cloud_rfp.pdf\"))\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, LogEvent):\n",
    "        if event.delta:\n",
    "            print(event.msg, end=\"\")\n",
    "        else:\n",
    "            print(event.msg)\n",
    "\n",
    "response = await handler\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_parse",
   "language": "python",
   "name": "llama_parse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
